{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary of Data Preparation Steps for DDPM Image Generation**\n",
        "*This document outlines the key steps for preparing the Flowers and CelebA datasets to train a Denoising Diffusion Probabilistic Model (DDPM), explaining each step's purpose.*\n",
        "\n",
        "# **Steps**\n",
        "\n",
        "* **Image Resizing**\n",
        "  * Purpose: Standardize all images to a consistent resolution (e.g., 256x256 pixels) to ensure uniform input shape for the model, which is essential for stable DDPM training.\n",
        "  * Implementation: We resize images to 256x256 pixels using transforms.Resize((256, 256)).\n",
        "\n",
        "* **Normalization**\n",
        "  * Purpose: Scale image pixel values to the range\n",
        "[\n",
        "−\n",
        "1\n",
        ",\n",
        "1\n",
        "]\n",
        "[−1,1] to prepare images for noise addition and removal in the DDPM pipeline, which typically performs best within this range.\n",
        "  * Implementation: We apply transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]).\n",
        "\n",
        "* **Data Augmentation (Training Only)**\n",
        "\n",
        "  * Purpose: Increase variability and robustness in the training data, helping the model generalize better by introducing transformations such as random flips, rotations, and color adjustments.\n",
        "  * Implementation: Augmentations include RandomHorizontalFlip, RandomRotation, and ColorJitter. These are applied only to the training set.\n",
        "\n",
        "* **Dataset Splitting**\n",
        "  * Purpose: Divide the dataset into training, validation, and test sets to enable effective model evaluation and generalization testing.\n",
        "  * Implementation: We split each dataset into 80% training, 10% validation, and 10% test sets using train_test_split.\n",
        "\n",
        "* **DataLoader Creation**\n",
        "  * Purpose: Enable efficient, batched loading of data for model training and evaluation. Shuffling in the training DataLoader helps distribute data evenly across training iterations.\n",
        "  * Implementation: We create DataLoader instances for each split with a batch size of 32, shuffling enabled for training."
      ],
      "metadata": {
        "id": "HD0-0aSAx6Gj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "goq3p5pDoKyb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "!kaggle datasets download -d alxmamaev/flowers-recognition\n",
        "!kaggle datasets download -d jessicali9530/celeba-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LtzdKbttUp6",
        "outputId": "517cd876-4c83-494d-b299-4bd642540e7c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Dataset URL: https://www.kaggle.com/datasets/alxmamaev/flowers-recognition\n",
            "License(s): unknown\n",
            "Downloading flowers-recognition.zip to /content\n",
            " 90% 202M/225M [00:01<00:00, 132MB/s]\n",
            "100% 225M/225M [00:01<00:00, 147MB/s]\n",
            "Dataset URL: https://www.kaggle.com/datasets/jessicali9530/celeba-dataset\n",
            "License(s): other\n",
            "Downloading celeba-dataset.zip to /content\n",
            " 98% 1.31G/1.33G [00:06<00:00, 211MB/s]\n",
            "100% 1.33G/1.33G [00:06<00:00, 204MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('flowers-recognition.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('flowers-recognition')\n",
        "\n",
        "with zipfile.ZipFile('celeba-dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('celeba')"
      ],
      "metadata": {
        "id": "2VPuVd1Dtx0-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flowers_dataset_path = \"flowers-recognition/flowers\"\n",
        "celeba_images_path = \"celeba/img_align_celeba\"\n",
        "celeba_attributes_path = \"celeba/list_attr_celeba.csv\"\n",
        "\n",
        "common_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])\n",
        "\n",
        "augmentation_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])\n",
        "\n",
        "def split_dataset(dataset, val_split=0.1, test_split=0.1):\n",
        "    train_size = 1 - (val_split + test_split)\n",
        "    train_idx, test_idx = train_test_split(range(len(dataset)), test_size=test_split)\n",
        "    train_idx, val_idx = train_test_split(train_idx, test_size=val_split / train_size)\n",
        "    return Subset(dataset, train_idx), Subset(dataset, val_idx), Subset(dataset, test_idx)\n",
        "\n",
        "flowers_dataset = ImageFolder(root=flowers_dataset_path, transform=common_transforms)\n",
        "flowers_train, flowers_val, flowers_test = split_dataset(flowers_dataset)\n",
        "\n",
        "flowers_train_loader = DataLoader(flowers_train, batch_size=32, shuffle=True, num_workers=4)\n",
        "flowers_val_loader = DataLoader(flowers_val, batch_size=32, shuffle=False, num_workers=4)\n",
        "flowers_test_loader = DataLoader(flowers_test, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "celeba_images = ImageFolder(root=celeba_images_path, transform=common_transforms)\n",
        "celeba_train, celeba_val, celeba_test = split_dataset(celeba_images)\n",
        "\n",
        "celeba_train_loader = DataLoader(celeba_train, batch_size=32, shuffle=True, num_workers=4)\n",
        "celeba_val_loader = DataLoader(celeba_val, batch_size=32, shuffle=False, num_workers=4)\n",
        "celeba_test_loader = DataLoader(celeba_test, batch_size=32, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "oCVvhFjWqldo"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}